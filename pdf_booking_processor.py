##pdf_booking_processor.py
# 
# ‚úÖ FUNCIONALIDADE: Processamento de PDFs de Booking
# Extrai dados de PDFs de Booking recebidos por e-mail e processa para inser√ß√£o na F_CON_RETURN_CARRIERS
# 
# Funcionalidades implementadas:
# - Extra√ß√£o de texto de PDFs usando PyPDF2
# - Identifica√ß√£o autom√°tica de armador/carrier baseado no conte√∫do
# - Extra√ß√£o de dados espec√≠ficos usando regex patterns
# - Valida√ß√£o e normaliza√ß√£o de dados extra√≠dos
# - Interface de valida√ß√£o para o usu√°rio
# - Inser√ß√£o na tabela F_CON_RETURN_CARRIERS com status "Received from Carrier"
# 
import streamlit as st
import pandas as pd
import re
from datetime import datetime
from database import get_database_connection, insert_return_carrier_from_ui
from sqlalchemy import text
import uuid

try:
    import pdfplumber
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    st.error("‚ö†Ô∏è pdfplumber n√£o est√° instalado. Execute: pip install pdfplumber")

# Padr√µes de extra√ß√£o por armador/carrier
CARRIER_PATTERNS = {
    "MAERSK": {
        "booking_reference": [
            r"Booking No\.?:\s*(\d+)",  # Padr√£o espec√≠fico Maersk
            r"Booking\s+(?:Reference|Number|No)[\s:]+([A-Z0-9]{8,12})",
            r"(\d{9})",  # Padr√£o gen√©rico para n√∫meros de 9 d√≠gitos (como 243601857)
        ],
        "vessel_name": [
            r"MVS\s+([^(]+?)(?:\s*\([^)]*\))?\s+(\d+[A-Z]?)",  # Padr√£o MVS Maersk
            r"Vessel[\s:]+([A-Z\s]+)",
            r"Ship[\s:]+([A-Z\s]+)",
        ],
        "voyage": [
            r"MVS\s+[^(]+?\s+(\d+[A-Z]?)",  # Extrai voyage do padr√£o MVS
            r"Voyage[\s:]+([A-Z0-9]+)",
        ],
        "quantity": [
            r"(\d+)\s+40\s+DRY",  # Padr√£o espec√≠fico Maersk
            r"(\d+)\s+(?:20|40|45)\s+([A-Z/ ]+?)\b",  # Padr√£o gen√©rico
            r"Quantity[\s:]+(\d+)",
        ],
        "pol": [
            r"From:\s*([^,\n]+,[^,\n]+,[^,\n]+)",  # Padr√£o espec√≠fico Maersk
            r"Port\s+of\s+Loading[\s:]+([A-Z\s,]+)",
            r"POL[\s:]+([A-Z\s,]+)",
        ],
        "pod": [
            r"(?:To|TO)\s*:\s*([^,\n]+(?:,[^,\n]+)?(?:,[^,\n]+)?)",  # Padr√£o espec√≠fico Maersk
            r"Port\s+of\s+Discharge[\s:]+([A-Z\s,]+)",
            r"POD[\s:]+([A-Z\s,]+)",
        ],
        "etd": [
            r"(\d{4}-\d{2}-\d{2})\s+\d{4}-\d{2}-\d{2}",  # Primeira data do padr√£o MVS
            r"ETD[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
        ],
        "eta": [
            r"\d{4}-\d{2}-\d{2}\s+(\d{4}-\d{2}-\d{2})",  # Segunda data do padr√£o MVS
            r"ETA[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
        ],
        "cargo_type": [
            r"(?:Customer Cargo|Commodity Description)\s*:\s*(.+?)(?:\n|Service Contract|Price Owner|$)",
        ],
        "gross_weight": [
            r"Gross Weight.*?([\d\.]+)\s*KGS",
        ],
    },
    "HAPAG-LLOYD": {
        "booking_reference": [
            r"Booking\s+(?:Reference|Number|No)[\s:]+([A-Z0-9]{8,12})",
            r"BKG\s+(?:REF|NO)[\s:]+([A-Z0-9]{8,12})",
            r"([A-Z]{4}\d{7})",  # Padr√£o t√≠pico HAPAG
        ],
        "vessel_name": [
            r"Vessel[\s:]+([A-Z\s]+)",
            r"Ship[\s:]+([A-Z\s]+)",
            r"M/V\s+([A-Z\s]+)",
        ],
        "voyage": [
            r"Voyage[\s:]+([A-Z0-9]+)",
            r"Voy[\s:]+([A-Z0-9]+)",
        ],
        "quantity": [
            r"(\d+)\s*x\s*\d+['\s]*(?:containers?|cntr|ctr)",
            r"Quantity[\s:]+(\d+)",
            r"(\d+)\s*(?:containers?|cntr|ctr)",
        ],
        "pol": [
            r"Port\s+of\s+Loading[\s:]+([A-Z\s,]+)",
            r"POL[\s:]+([A-Z\s,]+)",
            r"Loading\s+Port[\s:]+([A-Z\s,]+)",
        ],
        "pod": [
            r"Port\s+of\s+Discharge[\s:]+([A-Z\s,]+)",
            r"POD[\s:]+([A-Z\s,]+)",
            r"Discharge\s+Port[\s:]+([A-Z\s,]+)",
        ],
        "etd": [
            r"ETD[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
            r"Departure[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
        ],
        "eta": [
            r"ETA[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
            r"Arrival[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
        ],
    },
    "MSC": {
        "booking_reference": [
            r"Booking\s+(?:Reference|Number|No)[\s:]+([A-Z0-9]{8,12})",
            r"([A-Z]{3}\d{7})",  # Padr√£o t√≠pico MSC
        ],
        "vessel_name": [
            r"Vessel[\s:]+([A-Z\s]+)",
            r"Ship[\s:]+([A-Z\s]+)",
        ],
        "voyage": [
            r"Voyage[\s:]+([A-Z0-9]+)",
        ],
        "quantity": [
            r"(\d+)\s*x\s*\d+['\s]*(?:containers?|cntr|ctr)",
            r"Quantity[\s:]+(\d+)",
        ],
        "pol": [
            r"Port\s+of\s+Loading[\s:]+([A-Z\s,]+)",
            r"POL[\s:]+([A-Z\s,]+)",
        ],
        "pod": [
            r"Port\s+of\s+Discharge[\s:]+([A-Z\s,]+)",
            r"POD[\s:]+([A-Z\s,]+)",
        ],
        "etd": [
            r"ETD[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
        ],
        "eta": [
            r"ETA[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
        ],
    },
    "GENERIC": {  # Padr√µes gen√©ricos para outros armadores
        "booking_reference": [
            r"Booking\s+(?:Reference|Number|No)[\s:]+([A-Z0-9]{6,15})",
            r"BKG\s+(?:REF|NO)[\s:]+([A-Z0-9]{6,15})",
            r"Reference[\s:]+([A-Z0-9]{6,15})",
        ],
        "vessel_name": [
            r"Vessel[\s:]+([A-Z\s]+)",
            r"Ship[\s:]+([A-Z\s]+)",
            r"M/V\s+([A-Z\s]+)",
        ],
        "voyage": [
            r"Voyage[\s:]+([A-Z0-9]+)",
            r"Voy[\s:]+([A-Z0-9]+)",
        ],
        "quantity": [
            r"(\d+)\s*x\s*\d+['\s]*(?:containers?|cntr|ctr)",
            r"Quantity[\s:]+(\d+)",
            r"(\d+)\s*(?:containers?|cntr|ctr)",
        ],
        "pol": [
            r"Port\s+of\s+Loading[\s:]+([A-Z\s,]+)",
            r"POL[\s:]+([A-Z\s,]+)",
            r"Loading\s+Port[\s:]+([A-Z\s,]+)",
        ],
        "pod": [
            r"Port\s+of\s+Discharge[\s:]+([A-Z\s,]+)",
            r"POD[\s:]+([A-Z\s,]+)",
            r"Discharge\s+Port[\s:]+([A-Z\s,]+)",
        ],
        "etd": [
            r"ETD[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
            r"Departure[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
        ],
        "eta": [
            r"ETA[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
            r"Arrival[\s:]+(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})",
        ],
    }
}

def extract_text_from_pdf(pdf_file):
    """
    Extrai texto de um arquivo PDF.
    
    Args:
        pdf_file: Arquivo PDF (bytes ou file-like object)
    
    Returns:
        str: Texto extra√≠do do PDF
    """
    if not PDF_AVAILABLE:
        return None
    
    try:
        # Se √© bytes, cria um file-like object
        if isinstance(pdf_file, bytes):
            from io import BytesIO
            pdf_file = BytesIO(pdf_file)
        
        # Reseta o ponteiro para o in√≠cio
        pdf_file.seek(0)
        
        text = ""
        with pdfplumber.open(pdf_file) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        
        return text.strip()
    
    except Exception as e:
        st.error(f"Erro ao extrair texto do PDF: {str(e)}")
        return None

def identify_carrier(text):
    """
    Identifica o armador/carrier baseado no conte√∫do do PDF.
    
    Args:
        text (str): Texto extra√≠do do PDF
    
    Returns:
        str: Nome do carrier identificado ou "GENERIC"
    """
    text_upper = text.upper()
    
    # Padr√µes de identifica√ß√£o de carriers
    carrier_indicators = {
        "HAPAG-LLOYD": ["HAPAG", "LLOYD", "HAPAG-LLOYD"],
        "MAERSK": ["MAERSK", "A.P. MOLLER", "APM"],
        "MSC": ["MSC", "MEDITERRANEAN SHIPPING"],
        "CMA CGM": ["CMA", "CGM", "CMA CGM"],
        "COSCO": ["COSCO", "CHINA COSCO"],
        "EVERGREEN": ["EVERGREEN", "EMC"],
    }
    
    for carrier, indicators in carrier_indicators.items():
        for indicator in indicators:
            if indicator in text_upper:
                return carrier
    
    return "GENERIC"

def extract_data_with_patterns(text, patterns):
    """
    Extrai dados usando os padr√µes regex definidos.
    
    Args:
        text (str): Texto do PDF
        patterns (dict): Dicion√°rio com padr√µes regex
    
    Returns:
        dict: Dados extra√≠dos
    """
    extracted_data = {}
    
    for field, regex_list in patterns.items():
        for regex_pattern in regex_list:
            try:
                match = re.search(regex_pattern, text, re.IGNORECASE | re.MULTILINE)
                if match:
                    extracted_data[field] = match.group(1).strip()
                    break  # Para no primeiro match encontrado
            except Exception:
                continue  # Continua para o pr√≥ximo padr√£o
    
    return extracted_data

def extract_maersk_data_old(text_content):
    """Extrai dados espec√≠ficos para PDFs da Maersk usando padr√µes MVS"""
    data = {}
    
    # Usar padr√µes espec√≠ficos da Maersk
    patterns = CARRIER_PATTERNS["MAERSK"]
    
    # Extrair dados b√°sicos
    for field, pattern_list in patterns.items():
        for pattern in pattern_list:
            match = re.search(pattern, text_content, re.IGNORECASE | re.MULTILINE)
            if match:
                if field == "vessel_name":
                    # Para Maersk, extrair vessel e voyage do padr√£o MVS
                    vessel_match = re.search(r"MVS\s+([^(]+?)(?:\s*\([^)]*\))?\s+(\d+[A-Z]?)", text_content)
                    if vessel_match:
                        # Limpar quebras de linha e espa√ßos extras do vessel name
                        vessel_name = vessel_match.group(1).strip()
                        # Remove quebras de linha primeiro
                        vessel_name = re.sub(r'\n+', ' ', vessel_name)   # Substitui quebras por espa√ßos
                        # Normaliza espa√ßos m√∫ltiplos em um s√≥
                        vessel_name = re.sub(r'\s+', ' ', vessel_name)
                        
                        # L√≥gica espec√≠fica para juntar partes de nomes que foram separadas
                        # Casos comuns: "MAERSK L ABREA" -> "MAERSK LABREA"
                        #               "MAERSK L O T A" -> "MAERSK LOTA"
                        
                        # Primeiro, junta sequ√™ncias de letras individuais (ex: "L O T A" -> "LOTA")
                        vessel_name = re.sub(r'\b([A-Z])\s+([A-Z])\s+([A-Z])\s+([A-Z])\s+([A-Z])\b', r'\1\2\3\4\5', vessel_name)
                        vessel_name = re.sub(r'\b([A-Z])\s+([A-Z])\s+([A-Z])\s+([A-Z])\b', r'\1\2\3\4', vessel_name)
                        vessel_name = re.sub(r'\b([A-Z])\s+([A-Z])\s+([A-Z])\b', r'\1\2\3', vessel_name)
                        vessel_name = re.sub(r'\b([A-Z])\s+([A-Z])\b', r'\1\2', vessel_name)
                        
                        # Depois, junta uma letra isolada com uma palavra seguinte
                        # Ex: "MAERSK L ABREA" -> "MAERSK LABREA"
                        vessel_name = re.sub(r'\b([A-Z])\s+([A-Z]{2,})\b', r'\1\2', vessel_name)
                        
                        data["vessel_name"] = vessel_name.strip()
                        data["voyage"] = vessel_match.group(2).strip()
                    else:
                        data["vessel_name"] = match.group(1).strip()
                elif field == "quantity":
                    # Para Maersk, extrair quantidade espec√≠fica
                    qty_match = re.search(r"(\d+)\s+40\s+DRY", text_content)
                    if qty_match:
                        data["quantity"] = qty_match.group(1).strip()
                    else:
                        data["quantity"] = match.group(1).strip()
                else:
                    data[field] = match.group(1).strip()
                break
    
    # Extrair ETD e ETA do padr√£o MVS (antes de processar POL/POD)
    mvs_pattern = r"(\d{4}-\d{2}-\d{2})\s+(\d{4}-\d{2}-\d{2})"
    mvs_match = re.search(mvs_pattern, text_content)
    if mvs_match:
        data["etd"] = mvs_match.group(1)
        data["eta"] = mvs_match.group(2).strip()
    
    # Extrair POL e POD usando padr√µes mais espec√≠ficos da Maersk
    # POL (From:) - Fun√ß√£o similar ao POD
    def extract_maersk_pol(text_content):
        """Extrai POL da Maersk capturando o texto completo ap√≥s 'From:'"""
        # Regex que captura tudo at√© o pr√≥ximo campo conhecido (deve parar antes de "To:")
        from_pattern = r"(?:From|FROM)\s*:\s*(.+?)(?=To:|Booking No|$)"
        from_match = re.search(from_pattern, text_content, re.IGNORECASE | re.MULTILINE | re.DOTALL)
        
        if from_match:
            port_text = from_match.group(1).strip()
            
            # Remove quebras de linha e normaliza espa√ßos
            port_clean = re.sub(r'\n+', ' ', port_text)
            port_clean = re.sub(r'\s+', ' ', port_clean)
            port_clean = port_clean.strip()
            
            # Remove campos que n√£o s√£o parte do porto
            port_clean = re.sub(r'Contact Name.*$', '', port_clean, flags=re.IGNORECASE)
            port_clean = re.sub(r'Booked by Ref.*$', '', port_clean, flags=re.IGNORECASE)
            port_clean = port_clean.strip()
            
            # Aplica a mesma l√≥gica de limpeza do POD
            # Casos espec√≠ficos conhecidos para POL
            port_clean = re.sub(r'\bSao\s+P\s+aulo\b', 'Sao Paulo', port_clean, flags=re.IGNORECASE)
            port_clean = re.sub(r'\bB\s+r\s+azi\s+l\b', 'Brazil', port_clean, flags=re.IGNORECASE)
            
            # Junta letras isoladas que foram separadas incorretamente
            port_clean = re.sub(r'\b([A-Z])\s+([A-Z])\b', r'\1\2', port_clean)
            port_clean = re.sub(r'\b([A-Z])\s+([a-z]+)\s+([a-z]+)\b', r'\1\2\3', port_clean)
            
            # Junta palavras quebradas comuns
            port_clean = re.sub(r'\b([A-Z][a-z]+)\s+([a-z]+)\b', r'\1\2', port_clean)
            
            # Junta letras individuais com palavras seguintes
            port_clean = re.sub(r'\b([A-Z])\s+([a-z]{2,})\b', r'\1\2', port_clean)
            
            return port_clean
        
        return None
    
    # Extrai POL usando a fun√ß√£o melhorada
    pol_text = extract_maersk_pol(text_content)
    if pol_text:
        data["pol"] = pol_text
    
    # POD (To:) - Fun√ß√£o melhorada para lidar com quebras de linha
    def extract_maersk_pod(text_content):
        """Extrai POD da Maersk capturando o texto completo ap√≥s 'To:'"""
        # Regex que funciona: captura tudo at√© o pr√≥ximo campo conhecido
        to_pattern = r"(?:To|TO)\s*:\s*(.+?)(?=Contact Name|Booked by Ref|Customer Cargo|Booking No)"
        to_match = re.search(to_pattern, text_content, re.IGNORECASE | re.MULTILINE | re.DOTALL)
        
        if to_match:
            port_text = to_match.group(1).strip()
            
            # Remove quebras de linha e normaliza espa√ßos
            port_clean = re.sub(r'\n+', ' ', port_text)
            port_clean = re.sub(r'\s+', ' ', port_clean)
            port_clean = port_clean.strip()
            
            # L√≥gica inteligente para juntar palavras quebradas preservando nomes de cidades
            
            # Casos espec√≠ficos conhecidos
            port_clean = re.sub(r'\bI\s+sk\s+enderun\b', 'Iskenderun', port_clean, flags=re.IGNORECASE)
            port_clean = re.sub(r'\bHo\s+Chi\s+Minh\s+Ci\s+T\s+Y\b', 'Ho Chi Minh City', port_clean, flags=re.IGNORECASE)
            
            # Junta letras isoladas que foram separadas incorretamente
            # Ex: "T Y" -> "TY", "T urk ey" -> "Turkey"
            port_clean = re.sub(r'\b([A-Z])\s+([A-Z])\b', r'\1\2', port_clean)
            port_clean = re.sub(r'\b([A-Z])\s+([a-z]+)\s+([a-z]+)\b', r'\1\2\3', port_clean)
            
            # Junta palavras quebradas comuns em PDFs
            # Ex: "Ci ty" -> "City", "Tur key" -> "Turkey"
            port_clean = re.sub(r'\b([A-Z][a-z]+)\s+([a-z]+)\b', r'\1\2', port_clean)
            
            # Junta letras individuais com palavras seguintes
            # Ex: "I sk" -> "Isk", mas preserva espa√ßos entre palavras completas
            port_clean = re.sub(r'\b([A-Z])\s+([a-z]{2,})\b', r'\1\2', port_clean)
            
            return port_clean
        
        # Fallback: m√©todo anterior se a regex n√£o funcionar
        to_match = re.search(r"(?:To|TO)\s*:", text_content, re.IGNORECASE | re.MULTILINE)
        if not to_match:
            print("DEBUG: 'To:' n√£o encontrado")
            return None
        
        print(f"DEBUG: 'To:' encontrado na posi√ß√£o {to_match.end()}")
        
        # Obt√©m a posi√ß√£o do "To:"
        to_pos = to_match.end()
        
        # Extrai o texto ap√≥s "To:" at√© encontrar o pr√≥ximo campo
        remaining_text = text_content[to_pos:]
        print(f"DEBUG: Texto restante ap√≥s 'To:': '{remaining_text[:100]}...'")
        
        # Procura pelo pr√≥ximo campo (Contact Name, Booked by Ref, Customer Cargo, etc.)
        next_field_match = re.search(r'(?:Contact Name|Booked by Ref|Customer Cargo|Booking No|Service Contract|Price Owner)', remaining_text, re.IGNORECASE)
        
        if next_field_match:
            # Extrai apenas o texto do porto
            port_text = remaining_text[:next_field_match.start()].strip()
            print(f"DEBUG: Porto extra√≠do (com pr√≥ximo campo): '{port_text}'")
        else:
            # Se n√£o encontrar pr√≥ximo campo, pega as pr√≥ximas linhas
            lines = remaining_text.split('\n')
            port_lines = []
            for line in lines[:10]:  # Limita a 10 linhas para evitar capturar muito
                line = line.strip()
                if line and not any(keyword in line for keyword in ['Contact Name', 'Booked by Ref', 'Customer Cargo', 'Booking No']):
                    port_lines.append(line)
                if len(port_lines) >= 5:  # Limita a 5 linhas para o porto
                    break
            port_text = ' '.join(port_lines)
            print(f"DEBUG: Porto extra√≠do (sem pr√≥ximo campo): '{port_text}'")
        
        # Limpa o texto do porto
        if port_text:
            print(f"DEBUG: Porto antes da limpeza: '{port_text}'")
            
            # Remove quebras de linha e normaliza espa√ßos
            port_clean = re.sub(r'\n+', ' ', port_text)  # Remove quebras de linha primeiro
            port_clean = re.sub(r'\s+', ' ', port_clean)  # Normaliza espa√ßos m√∫ltiplos
            # Remove campos que n√£o s√£o parte do porto
            port_clean = re.sub(r'Contact Name.*$', '', port_clean, flags=re.IGNORECASE)
            port_clean = re.sub(r'Booked by Ref.*$', '', port_clean, flags=re.IGNORECASE)
            port_clean = re.sub(r'Customer Cargo.*$', '', port_clean, flags=re.IGNORECASE)
            port_clean = port_clean.strip()
            
            print(f"DEBUG: Porto ap√≥s limpeza b√°sica: '{port_clean}'")
            
            # L√≥gica simplificada para juntar palavras quebradas
            # Caso espec√≠fico: "I sk enderun,T urk ey" -> "Iskenderun,Turkey"
            
            # Abordagem direta: substitui padr√µes espec√≠ficos
            port_clean = re.sub(r'\bI\s+sk\b', 'Isk', port_clean)
            print(f"DEBUG: Ap√≥s substituir I+sk: '{port_clean}'")
            
            port_clean = re.sub(r'\benderun,T\s+urk\s+ey\b', 'enderun,Turkey', port_clean)
            print(f"DEBUG: Ap√≥s substituir enderun,T+urk+ey: '{port_clean}'")
            
            # Caso geral: junta palavras que come√ßam com mai√∫scula seguida de min√∫scula
            port_clean = re.sub(r'\b([A-Z])\s+([a-z]{2,})\b', r'\1\2', port_clean)
            print(f"DEBUG: Ap√≥s regex geral: '{port_clean}'")
            
            # Junta palavras que terminam com min√∫scula seguidas de min√∫scula
            port_clean = re.sub(r'\b([a-z]+)\s+([a-z]{2,})\b', r'\1\2', port_clean)
            print(f"DEBUG: Ap√≥s regex min√∫scula+min√∫scula: '{port_clean}'")
            
            print(f"DEBUG: Porto final: '{port_clean}'")
            return port_clean
        
        print("DEBUG: Nenhum texto de porto encontrado")
        return None
    
    # Extrai POD usando a fun√ß√£o melhorada
    pod_text = extract_maersk_pod(text_content)
    if pod_text:
        data["pod"] = pod_text
    
    # Extrair dados adicionais espec√≠ficos da Maersk
    # Cargo Type
    cargo_match = re.search(r"(?:Customer Cargo|Commodity Description)\s*:\s*(.+?)(?:\n|Service Contract|Price Owner|$)", text_content, re.IGNORECASE | re.MULTILINE)
    if cargo_match:
        cargo_text = cargo_match.group(1).strip()
        # Limpar quebras de linha
        cargo_clean = re.sub(r'\s+', ' ', cargo_text)
        data["cargo_type"] = cargo_clean.strip()
    
    # Gross Weight
    weight_match = re.search(r"Gross Weight.*?([\d\.]+)\s*KGS", text_content, re.IGNORECASE)
    if weight_match:
        data["gross_weight"] = weight_match.group(1).strip()
    
    # Document Type Detection
    doc_type_keywords = [
        ("BOOKING AMENDMENT", "BOOKING AMENDMENT"),
        ("BOOKING CONFIRMATION", "BOOKING CONFIRMATION"),
        ("BOOKING CANCELLATION", "BOOKING CANCELLATION"),
        ("ARCHIVE COPY", "ARCHIVE COPY")
    ]
    for keyword, label in doc_type_keywords:
        if keyword in text_content.upper():
            data["document_type"] = label
            break
    
    # Limpar campos de porto para formato "Cidade,Estado,Pa√≠s"
    if "pol" in data:
        data["pol"] = clean_port_field(data["pol"])
    
    if "pod" in data:
        data["pod"] = clean_port_field(data["pod"])
    
    return data

def extract_maersk_data(text_content):
    """Extrai dados espec√≠ficos para PDFs da Maersk usando as regex do c√≥digo de exemplo e pdfplumber"""
    data = {}
    
    # Regex baseadas no c√≥digo de exemplo que funciona
    patterns = {
        "booking_reference": r"Booking No\.?:\s*(\d+)",
        "from": r"From:\s*([^,\n]+,[^,\n]+,[^,\n]+)",
        "to": r"(?:To|TO)\s*:\s*([^,\n]+(?:,[^,\n]+)?(?:,[^,\n]+)?)",
        "cargo_type": r"(?:Customer Cargo|Commodity Description)\s*:\s*(.+?)(?:\n|Service Contract|Price Owner|$)",
        "quantity": r"(\d+)\s+40\s+DRY",
        "gross_weight": r"Gross Weight.*?([\d\.]+)\s*KGS",
    }
    
    # Extrair dados b√°sicos usando as regex do c√≥digo de exemplo
    for field, pattern in patterns.items():
        try:
            match = re.search(pattern, text_content, re.DOTALL | re.MULTILINE)
            if match:
                data[field] = match.group(1).strip()
        except Exception:
            data[field] = None
    
    # Mapear campos para nomes esperados
    if "booking_reference" in data:
        data["booking_reference"] = data["booking_reference"]
    if "from" in data:
        data["pol"] = data.pop("from")  # Remove "from" e adiciona "pol"
    if "to" in data:
        data["pod"] = data.pop("to")    # Remove "to" e adiciona "pod"
    
    # Extrair ETD, ETA, Vessel e Voy No. usando a fun√ß√£o do c√≥digo de exemplo
    def extract_etd_eta_vessel(text):
        lines = text.split('\n')
        etd_eta_lines = []
        
        for line in lines:
            if re.search(r'\d{4}-\d{2}-\d{2}', line):
                if 'MVS' in line:
                    etd_eta_lines.append(line.strip())
        
        if not etd_eta_lines:
            return None, None, None, None
        
        # Extrair informa√ß√µes da primeira linha MVS
        first_line = etd_eta_lines[0]
        first_dates = re.findall(r'\d{4}-\d{2}-\d{2}', first_line)
        first_etd = first_dates[0] if first_dates else None
        
        # Padr√µes para Vessel e Voy
        vessel_patterns = [
            r'MVS\s+PENDING MOTHER VSL\s+FLEX\s+(\d{4}-\d{2}-\d{2})',
            r'MVS\s+([^(]+?)(?:\s*\([^)]*\))?\s+(\d+[A-Z]?)',
        ]
        
        first_vessel = None
        first_voy = None
        
        # Tentar padr√£o FLEX primeiro
        match = re.search(vessel_patterns[0], first_line)
        if match:
            first_vessel = "PENDING MOTHER VSL"
            first_voy = "FLEX"
        else:
            # Tentar padr√£o padr√£o
            match = re.search(vessel_patterns[1], first_line)
            if match:
                first_vessel = match.group(1).strip()
                first_voy = match.group(2)
        
        # Extrair informa√ß√µes da √∫ltima linha MVS
        last_line = etd_eta_lines[-1]
        last_dates = re.findall(r'\d{4}-\d{2}-\d{2}', last_line)
        last_eta = last_dates[-1] if last_dates else None
        
        return first_etd, last_eta, first_vessel, first_voy
    
    # Extrair ETD, ETA, Vessel e Voy
    first_etd, last_eta, first_vessel, first_voy = extract_etd_eta_vessel(text_content)
    if first_etd:
        data["etd"] = first_etd
    if last_eta:
        data["eta"] = last_eta
    if first_vessel:
        data["vessel_name"] = first_vessel
    if first_voy:
        data["voyage"] = first_voy
    
    # Document Type Detection
    doc_type_keywords = [
        ("BOOKING AMENDMENT", "BOOKING AMENDMENT"),
        ("BOOKING CONFIRMATION", "BOOKING CONFIRMATION"),
        ("BOOKING CANCELLATION", "BOOKING CANCELLATION"),
        ("ARCHIVE COPY", "ARCHIVE COPY")
    ]
    for keyword, label in doc_type_keywords:
        if keyword in text_content.upper():
            data["document_type"] = label
            break
    
    # Limpar campos de porto usando a fun√ß√£o do c√≥digo de exemplo
    def clean_port_field_maersk(value):
        if not value:
            return None
        # remover c√≥digos ou complementos entre par√™nteses
        no_paren = re.sub(r"\s*\([^)]*\)", "", value)
        # quebrar por v√≠rgula e pegar no m√°ximo 3 partes
        parts = [p.strip() for p in no_paren.split(",") if p.strip()]
        if not parts:
            return None
        return ",".join(parts[:3])
    
    if "pol" in data and data["pol"]:
        data["pol"] = clean_port_field_maersk(data["pol"])
    
    if "pod" in data and data["pod"]:
        data["pod"] = clean_port_field_maersk(data["pod"])
    
    return data

def extract_hapag_lloyd_data(text_content):
    """Extrai dados espec√≠ficos para PDFs da Hapag-Lloyd"""
    data = {}
    
    # Usar padr√µes espec√≠ficos da Hapag-Lloyd
    patterns = CARRIER_PATTERNS["HAPAG-LLOYD"]
    
    # Extrair dados b√°sicos
    for field, pattern_list in patterns.items():
        for pattern in pattern_list:
            match = re.search(pattern, text_content, re.IGNORECASE | re.MULTILINE)
            if match:
                data[field] = match.group(1).strip()
                break
    
    return data

def extract_msc_data(text_content):
    """Extrai dados espec√≠ficos para PDFs da MSC"""
    data = {}
    
    # Usar padr√µes espec√≠ficos da MSC
    patterns = CARRIER_PATTERNS["MSC"]
    
    # Extrair dados b√°sicos
    for field, pattern_list in patterns.items():
        for pattern in pattern_list:
            match = re.search(pattern, text_content, re.IGNORECASE | re.MULTILINE)
            if match:
                data[field] = match.group(1).strip()
                break
    
    return data

def extract_cma_cgm_data(text_content):
    """Extrai dados espec√≠ficos para PDFs da CMA CGM"""
    data = {}
    
    # Usar padr√µes espec√≠ficos da CMA CGM
    patterns = CARRIER_PATTERNS["GENERIC"]  # Usar padr√µes gen√©ricos por enquanto
    
    # Extrair dados b√°sicos
    for field, pattern_list in patterns.items():
        for pattern in pattern_list:
            match = re.search(pattern, text_content, re.IGNORECASE | re.MULTILINE)
            if match:
                data[field] = match.group(1).strip()
                break
    
    return data

def extract_cosco_data(text_content):
    """Extrai dados espec√≠ficos para PDFs da COSCO"""
    data = {}
    
    # Usar padr√µes espec√≠ficos da COSCO
    patterns = CARRIER_PATTERNS["GENERIC"]  # Usar padr√µes gen√©ricos por enquanto
    
    # Extrair dados b√°sicos
    for field, pattern_list in patterns.items():
        for pattern in pattern_list:
            match = re.search(pattern, text_content, re.IGNORECASE | re.MULTILINE)
            if match:
                data[field] = match.group(1).strip()
                break
    
    return data

def extract_evergreen_data(text_content):
    """Extrai dados espec√≠ficos para PDFs da Evergreen"""
    data = {}
    
    # Usar padr√µes espec√≠ficos da Evergreen
    patterns = CARRIER_PATTERNS["GENERIC"]  # Usar padr√µes gen√©ricos por enquanto
    
    # Extrair dados b√°sicos
    for field, pattern_list in patterns.items():
        for pattern in pattern_list:
            match = re.search(pattern, text_content, re.IGNORECASE | re.MULTILINE)
            if match:
                data[field] = match.group(1).strip()
                break
    
    return data

def extract_generic_data(text_content):
    """Extrai dados usando padr√µes gen√©ricos para outros armadores"""
    data = {}
    
    # Usar padr√µes gen√©ricos
    patterns = CARRIER_PATTERNS["GENERIC"]
    
    # Extrair dados b√°sicos
    for field, pattern_list in patterns.items():
        for pattern in pattern_list:
            match = re.search(pattern, text_content, re.IGNORECASE | re.MULTILINE)
            if match:
                data[field] = match.group(1).strip()
                break
    
    return data

def clean_port_field(value):
    """Limpa campo de porto para formato 'Cidade,Estado,Pa√≠s'"""
    if not value:
        return None
    # remover c√≥digos ou complementos entre par√™nteses
    no_paren = re.sub(r"\s*\([^)]*\)", "", value)
    # quebrar por v√≠rgula e pegar no m√°ximo 3 partes
    parts = [p.strip() for p in no_paren.split(",") if p.strip()]
    if not parts:
        return None
    return ",".join(parts[:3])

def normalize_extracted_data(extracted_data):
    """
    Normaliza e valida os dados extra√≠dos.
    
    Args:
        extracted_data (dict): Dados extra√≠dos brutos
    
    Returns:
        dict: Dados normalizados
    """
    normalized = {}
    
    # Normaliza booking reference
    if "booking_reference" in extracted_data:
        booking_ref = extracted_data["booking_reference"]
        # Remove espa√ßos e caracteres especiais
        booking_ref = re.sub(r'[^\w]', '', booking_ref).upper()
        normalized["booking_reference"] = booking_ref
    
    # Normaliza vessel name
    if "vessel_name" in extracted_data:
        vessel = extracted_data["vessel_name"]
        # Remove prefixos comuns e normaliza
        vessel = re.sub(r'^(M/V|MV|MS)\s+', '', vessel, flags=re.IGNORECASE)
        normalized["vessel_name"] = vessel.strip().title()
    
    # Normaliza voyage
    if "voyage" in extracted_data:
        normalized["voyage"] = extracted_data["voyage"].upper()
    
    # Normaliza quantity
    if "quantity" in extracted_data:
        try:
            normalized["quantity"] = int(extracted_data["quantity"])
        except ValueError:
            normalized["quantity"] = 1  # Default
    
    # Normaliza portos
    for port_field in ["pol", "pod"]:
        if port_field in extracted_data:
            port = extracted_data[port_field]
            # Remove v√≠rgulas e normaliza
            port = re.sub(r',.*', '', port).strip().title()
            normalized[port_field] = port
    
    # Normaliza datas
    for date_field in ["etd", "eta"]:
        if date_field in extracted_data:
            date_str = extracted_data[date_field]
            try:
                # Tenta diferentes formatos de data
                for fmt in ["%d/%m/%Y", "%d-%m-%Y", "%m/%d/%Y", "%m-%d-%Y", "%d/%m/%y", "%d-%m-%y"]:
                    try:
                        date_obj = datetime.strptime(date_str, fmt)
                        normalized[date_field] = date_obj.strftime("%Y-%m-%d")
                        break
                    except ValueError:
                        continue
            except Exception:
                normalized[date_field] = date_str  # Mant√©m original se n√£o conseguir converter
    
    return normalized

def process_pdf_booking(pdf_content, farol_reference):
    """
    Processa um PDF de booking e extrai os dados relevantes.
    
    Args:
        pdf_content: Conte√∫do do PDF (bytes)
        farol_reference (str): Refer√™ncia do Farol
    
    Returns:
        dict: Dados extra√≠dos e processados
    """
    try:
        if not PDF_AVAILABLE:
            st.error("‚ö†Ô∏è PyPDF2 n√£o est√° dispon√≠vel para processamento de PDF")
            return None
        
        st.info("üìÑ Iniciando processamento do PDF...")
        
        # Extrai texto do PDF
        text = extract_text_from_pdf(pdf_content)
        if not text:
            st.error("‚ùå N√£o foi poss√≠vel extrair texto do PDF")
            return None
        
        st.success(f"üìù Texto extra√≠do com sucesso! ({len(text)} caracteres)")
        
        # Identifica o carrier
        carrier = identify_carrier(text)
        st.info(f"üö¢ Carrier identificado: **{carrier}**")
        
    except Exception as e:
        st.error(f"‚ùå Erro durante o processamento inicial: {str(e)}")
        return None
    
    # Extrai dados usando fun√ß√£o espec√≠fica do carrier
    if carrier == "MAERSK":
        extracted_data = extract_maersk_data(text)
    elif carrier == "HAPAG-LLOYD":
        extracted_data = extract_hapag_lloyd_data(text)
    elif carrier == "MSC":
        extracted_data = extract_msc_data(text)
    elif carrier == "CMA CGM":
        extracted_data = extract_cma_cgm_data(text)
    elif carrier == "COSCO":
        extracted_data = extract_cosco_data(text)
    elif carrier == "EVERGREEN":
        extracted_data = extract_evergreen_data(text)
    else:
        # Usar padr√µes gen√©ricos para outros armadores
        patterns = CARRIER_PATTERNS.get(carrier, CARRIER_PATTERNS["GENERIC"])
        extracted_data = extract_data_with_patterns(text, patterns)
    
    try:
        # Normaliza os dados
        st.info("üîÑ Normalizando dados extra√≠dos...")
        normalized_data = normalize_extracted_data(extracted_data)
        
        # Prepara dados para exibi√ß√£o/valida√ß√£o
        processed_data = {
            "farol_reference": farol_reference,
            "carrier": carrier,
            "booking_reference": normalized_data.get("booking_reference", ""),
            "vessel_name": normalized_data.get("vessel_name", ""),
            "voyage": normalized_data.get("voyage", ""),
            "quantity": normalized_data.get("quantity", 1),
            "pol": normalized_data.get("pol", ""),
            "pod": normalized_data.get("pod", ""),
            "etd": normalized_data.get("etd", ""),
            "eta": normalized_data.get("eta", ""),
            "cargo_type": extracted_data.get("cargo_type", ""),
            "gross_weight": extracted_data.get("gross_weight", ""),
            "document_type": extracted_data.get("document_type", ""),
            "extracted_text": text[:500] + "..." if len(text) > 500 else text  # Primeiros 500 caracteres para debug
        }
        
        st.success("‚úÖ Processamento conclu√≠do com sucesso!")
        st.info(f"üìä Dados extra√≠dos: Booking {processed_data.get('booking_reference')}, Vessel {processed_data.get('vessel_name')}")
        
        return processed_data
        
    except Exception as e:
        st.error(f"‚ùå Erro durante a normaliza√ß√£o: {str(e)}")
        return None

def display_pdf_validation_interface(processed_data):
    """
    Exibe interface para valida√ß√£o dos dados extra√≠dos do PDF.
    
    Args:
        processed_data (dict): Dados processados do PDF
    
    Returns:
        dict: Dados validados pelo usu√°rio ou None se cancelado
    """
    st.markdown("### üìã Valida√ß√£o dos Dados Extra√≠dos")
    st.markdown("Verifique e ajuste os dados extra√≠dos do PDF antes de salvar:")
    
    # Cria formul√°rio de valida√ß√£o
    with st.form("pdf_validation_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üö¢ Informa√ß√µes do Navio")
            carrier = st.selectbox(
                "Carrier/Armador",
                ["HAPAG-LLOYD", "MAERSK", "MSC", "CMA CGM", "COSCO", "EVERGREEN", "OTHER"],
                index=0 if processed_data["carrier"] == "GENERIC" else 
                      ["HAPAG-LLOYD", "MAERSK", "MSC", "CMA CGM", "COSCO", "EVERGREEN"].index(processed_data["carrier"]) 
                      if processed_data["carrier"] in ["HAPAG-LLOYD", "MAERSK", "MSC", "CMA CGM", "COSCO", "EVERGREEN"] else 6
            )
            
            vessel_name = st.text_input(
                "Nome do Navio",
                value=processed_data.get("vessel_name", ""),
                help="Nome da embarca√ß√£o"
            )
            
            voyage = st.text_input(
                "Voyage",
                value=processed_data.get("voyage", ""),
                help="C√≥digo da viagem"
            )
            
            booking_reference = st.text_input(
                "Booking Reference",
                value=processed_data.get("booking_reference", ""),
                help="Refer√™ncia do booking do armador"
            )
        
        with col2:
            st.markdown("#### üì¶ Informa√ß√µes da Carga")
            quantity = st.number_input(
                "Quantidade de Containers",
                min_value=1,
                value=int(processed_data.get("quantity", 1)),
                help="N√∫mero de containers"
            )
            
            pol = st.text_input(
                "Porto de Origem (POL)",
                value=processed_data.get("pol", ""),
                help="Port of Loading"
            )
            
            pod = st.text_input(
                "Porto de Destino (POD)",
                value=processed_data.get("pod", ""),
                help="Port of Discharge"
            )
            
            st.markdown("#### üìÖ Datas")
            etd = st.date_input(
                "ETD (Estimated Time of Departure)",
                value=datetime.strptime(processed_data.get("etd"), "%Y-%m-%d").date() 
                      if processed_data.get("etd") and processed_data.get("etd") != "" else None,
                help="Data estimada de partida"
            )
            
            eta = st.date_input(
                "ETA (Estimated Time of Arrival)",
                value=datetime.strptime(processed_data.get("eta"), "%Y-%m-%d").date() 
                      if processed_data.get("eta") and processed_data.get("eta") != "" else None,
                help="Data estimada de chegada"
            )
        
        # √Årea de texto extra√≠do (para debug/verifica√ß√£o)
        with st.expander("üîç Texto Extra√≠do (para verifica√ß√£o)", expanded=False):
            st.text_area(
                "Primeiros 500 caracteres do PDF:",
                value=processed_data.get("extracted_text", ""),
                height=150,
                disabled=True
            )
        
        # Bot√µes de a√ß√£o
        col1, col2 = st.columns([1, 1])
        with col1:
            submitted = st.form_submit_button("‚úÖ Validar e Salvar", type="primary", use_container_width=True)
        with col2:
            cancelled = st.form_submit_button("‚ùå Cancelar", use_container_width=True)
        
        if submitted:
            # Prepara dados validados
            validated_data = {
                "Farol Reference": processed_data["farol_reference"],
                "Voyage Carrier": carrier,
                "Voyage Code": voyage,
                "Vessel Name": vessel_name,
                "Splitted Booking Reference": booking_reference,
                "Quantity of Containers": quantity,
                "Port of Loading POL": pol,
                "Port of Delivery POD": pod,
                "ETD": etd.strftime("%Y-%m-%d") if etd else "",
                "ETA": eta.strftime("%Y-%m-%d") if eta else "",
                "Status": "Received from Carrier"  # Status espec√≠fico para PDFs processados
            }
            return validated_data
        
        if cancelled:
            return "CANCELLED"
    
    return None

def save_pdf_booking_data(validated_data):
    """
    Salva os dados validados do PDF na tabela F_CON_RETURN_CARRIERS.
    
    Args:
        validated_data (dict): Dados validados pelo usu√°rio
    
    Returns:
        bool: True se salvou com sucesso, False caso contr√°rio
    """
    try:
        # Usa a fun√ß√£o existente de inser√ß√£o, mas com status espec√≠fico
        success = insert_return_carrier_from_ui(validated_data, user_insert="PDF_PROCESSOR")
        
        if success:
            st.success("‚úÖ Dados do PDF salvos com sucesso na tabela F_CON_RETURN_CARRIERS!")
            st.info("üìã Status definido como: **Received from Carrier**")
            return True
        else:
            st.error("‚ùå Erro ao salvar dados do PDF")
            return False
    
    except Exception as e:
        st.error(f"‚ùå Erro ao salvar dados: {str(e)}")
        return False

def display_pdf_booking_section(farol_reference):
    """
    Exibe a se√ß√£o de processamento de PDF de Booking.
    Esta fun√ß√£o deve ser integrada na se√ß√£o de anexos existente.
    
    Args:
        farol_reference (str): Refer√™ncia do Farol
    """
    st.markdown("---")
    st.markdown("### üìÑ PDF Booking Processor")
    st.markdown("Upload e processe PDFs de Booking recebidos por e-mail para extrair dados automaticamente.")
    
    if not PDF_AVAILABLE:
        st.error("‚ö†Ô∏è **PyPDF2 n√£o est√° instalado**")
        st.markdown("Para usar esta funcionalidade, instale a depend√™ncia:")
        st.code("pip install PyPDF2")
        return
    
    # Upload de PDF espec√≠fico para booking
    uploaded_pdf = st.file_uploader(
        "üìÑ Selecione o PDF de Booking",
        type=['pdf'],
        key=f"pdf_booking_{farol_reference}",
        help="Selecione apenas PDFs de booking recebidos por e-mail"
    )
    
    if uploaded_pdf is not None:
        st.success(f"üìÑ PDF selecionado: **{uploaded_pdf.name}**")
        
        # Bot√£o para processar
        if st.button("üîç Processar PDF", key=f"process_pdf_{farol_reference}", type="primary"):
            with st.spinner("Processando PDF... Extraindo dados..."):
                # L√™ o conte√∫do do PDF
                pdf_content = uploaded_pdf.read()
                
                # Processa o PDF
                processed_data = process_pdf_booking(pdf_content, farol_reference)
                
                if processed_data:
                    # Armazena os dados processados no session_state para valida√ß√£o
                    st.session_state[f"processed_pdf_data_{farol_reference}"] = processed_data
                    st.rerun()
    
    # Interface de valida√ß√£o se h√° dados processados
    processed_data_key = f"processed_pdf_data_{farol_reference}"
    if processed_data_key in st.session_state:
        processed_data = st.session_state[processed_data_key]
        
        # Exibe interface de valida√ß√£o
        validated_data = display_pdf_validation_interface(processed_data)
        
        if validated_data == "CANCELLED":
            # Remove dados processados se cancelado
            del st.session_state[processed_data_key]
            st.rerun()
        elif validated_data:
            # Salva os dados validados
            if save_pdf_booking_data(validated_data):
                # Remove dados processados ap√≥s salvar
                del st.session_state[processed_data_key]
                st.balloons()  # Celebra√ß√£o visual
                st.rerun()
